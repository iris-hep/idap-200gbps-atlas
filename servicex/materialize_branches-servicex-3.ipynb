{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "180f4d32-e5c4-42f9-84e8-430034493a55",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awkward: 2.6.2\n",
      "dask-awkward: 2024.3.0\n",
      "uproot: 5.3.2\n",
      "hist: 2.7.2\n",
      "coffea: 2024.3.0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import awkward as ak\n",
    "import dask\n",
    "import dask_awkward as dak\n",
    "import hist.dask\n",
    "import coffea\n",
    "import numpy as np\n",
    "import uproot\n",
    "from dask.distributed import Client\n",
    "\n",
    "from coffea.nanoevents import NanoEventsFactory, PHYSLITESchema\n",
    "from coffea import dataset_tools\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# from servicex import ServiceXDataset\n",
    "from servicex import ServiceXSpec, General, Sample\n",
    "from servicex.uproot_raw.uproot_raw import UprootRawQuery\n",
    "from servicex.func_adl.func_adl_dataset import FuncADLQuery\n",
    "from func_adl_servicex_xaodr22 import FuncADLQueryPHYSLITE\n",
    "from func_adl_servicex_xaodr22 import (\n",
    "    cpp_float,\n",
    "    cpp_int,\n",
    "    cpp_vfloat,\n",
    "    cpp_vint,\n",
    ")\n",
    "from servicex.servicex_client import deliver\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from input_files import utils\n",
    "\n",
    "from dask.distributed import LocalCluster, Client, progress, performance_report\n",
    "\n",
    "# local: single thread, single worker\n",
    "cluster = LocalCluster(n_workers=1, processes=False, threads_per_worker=5)\n",
    "client = Client(cluster)\n",
    "\n",
    "# for UChicago\n",
    "# client = Client(\"tcp://dask-alheld-c58c6d0f-b.af-jupyter:8786\")  # update this to point to your own client!\n",
    "\n",
    "print(f\"awkward: {ak.__version__}\")\n",
    "print(f\"dask-awkward: {dak.__version__}\")\n",
    "print(f\"uproot: {uproot.__version__}\")\n",
    "print(f\"hist: {hist.__version__}\")\n",
    "print(f\"coffea: {coffea.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b019e93-f391-4811-b270-5c374b1e0ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_xcache(fpath):\n",
    "    import urllib\n",
    "    while True:\n",
    "        parsed = urllib.parse.urlparse(fpath)\n",
    "        if not parsed.scheme:\n",
    "            return parsed.geturl()\n",
    "        fpath = parsed.path\n",
    "    return fpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "614f02d7-1791-4df2-bb0d-7ab9022d69a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defined for direct access ??\n",
    "BRANCH_LIST = [\n",
    "    \"AnalysisJetsAuxDyn.pt\", \"AnalysisJetsAuxDyn.eta\", \"AnalysisJetsAuxDyn.phi\", \"AnalysisJetsAuxDyn.m\",\n",
    "    \"AnalysisElectronsAuxDyn.pt\", \"AnalysisElectronsAuxDyn.eta\", \"AnalysisElectronsAuxDyn.phi\",\n",
    "    \"AnalysisElectronsAuxDyn.m\", \"AnalysisMuonsAuxDyn.pt\", \"AnalysisMuonsAuxDyn.eta\",\n",
    "    \"AnalysisMuonsAuxDyn.phi\", \n",
    "    # \"AnalysisJetsAuxDyn.EnergyPerSampling\", # BAD! uproot can't write var * var * float32 to ROOT ??\n",
    "    # \"AnalysisJetsAuxDyn.SumPtTrkPt500\",  # BAD! uproot can't write var * var * float32 to ROOT ??\n",
    "    # \"AnalysisJetsAuxDyn.TrackWidthPt1000\",  # BAD! uproot can't write var * var * float32 to ROOT ??\n",
    "    \"PrimaryVerticesAuxDyn.z\", \"PrimaryVerticesAuxDyn.x\",\n",
    "    \"PrimaryVerticesAuxDyn.y\", \n",
    "    # \"AnalysisJetsAuxDyn.NumTrkPt500\", \"AnalysisJetsAuxDyn.NumTrkPt1000\", # BAD! uproot can't write var * var * int32 to ROOT ??\n",
    "    # \"AnalysisJetsAuxDyn.SumPtChargedPFOPt500\", # BAD! uproot can't write var * var * float32 to ROOT ??\n",
    "    \"AnalysisJetsAuxDyn.Timing\",\n",
    "    \"AnalysisJetsAuxDyn.JetConstitScaleMomentum_eta\", \"AnalysisJetsAuxDyn.ActiveArea4vec_eta\",\n",
    "    \"AnalysisJetsAuxDyn.DetectorEta\", \"AnalysisJetsAuxDyn.JetConstitScaleMomentum_phi\",\n",
    "    \"AnalysisJetsAuxDyn.ActiveArea4vec_phi\", \"AnalysisJetsAuxDyn.JetConstitScaleMomentum_m\",\n",
    "    \"AnalysisJetsAuxDyn.JetConstitScaleMomentum_pt\", \"AnalysisJetsAuxDyn.EMFrac\",\n",
    "    \"AnalysisJetsAuxDyn.Width\", \"AnalysisJetsAuxDyn.ActiveArea4vec_m\", \"AnalysisJetsAuxDyn.ActiveArea4vec_pt\",\n",
    "    \"AnalysisJetsAuxDyn.DFCommonJets_QGTagger_TracksWidth\", \"AnalysisJetsAuxDyn.PSFrac\",\n",
    "    \"AnalysisJetsAuxDyn.JVFCorr\", \"AnalysisJetsAuxDyn.DFCommonJets_QGTagger_TracksC1\",\n",
    "    \"AnalysisJetsAuxDyn.DFCommonJets_fJvt\", \"AnalysisJetsAuxDyn.DFCommonJets_QGTagger_NTracks\",\n",
    "    \"AnalysisJetsAuxDyn.GhostMuonSegmentCount\", \n",
    "    # \"AnalysisMuonsAuxDyn.muonSegmentLinks*\", # BAD! uproot can't write var * var * struct[{m_persKey: uint32, m_persIndex: uint32}]\n",
    "    # \"AnalysisMuonsAuxDyn.msOnlyExtrapolatedMuonSpectrometerTrackParticleLink*\", # Links don't crash the job but don't show up in output either\n",
    "    # \"AnalysisMuonsAuxDyn.extrapolatedMuonSpectrometerTrackParticleLink*\",\n",
    "    # \"AnalysisMuonsAuxDyn.inDetTrackParticleLink*\", \"AnalysisMuonsAuxDyn.muonSpectrometerTrackParticleLink*\",\n",
    "    \"AnalysisMuonsAuxDyn.momentumBalanceSignificance\", \"AnalysisMuonsAuxDyn.topoetcone20_CloseByCorr\",\n",
    "    \"AnalysisMuonsAuxDyn.scatteringCurvatureSignificance\", \"AnalysisMuonsAuxDyn.scatteringNeighbourSignificance\",\n",
    "    \"AnalysisMuonsAuxDyn.neflowisol20_CloseByCorr\", \"AnalysisMuonsAuxDyn.topoetcone20\",\n",
    "    \"AnalysisMuonsAuxDyn.topoetcone30\", \"AnalysisMuonsAuxDyn.topoetcone40\", \"AnalysisMuonsAuxDyn.neflowisol20\",\n",
    "    \"AnalysisMuonsAuxDyn.segmentDeltaEta\", \"AnalysisMuonsAuxDyn.DFCommonJetDr\",\n",
    "    # \"AnalysisMuonsAuxDyn.combinedTrackParticleLink*\", \n",
    "    \"AnalysisMuonsAuxDyn.InnerDetectorPt\",\n",
    "    \"AnalysisMuonsAuxDyn.MuonSpectrometerPt\", #\"AnalysisMuonsAuxDyn.clusterLink*\",\n",
    "    \"AnalysisMuonsAuxDyn.spectrometerFieldIntegral\", #\"AnalysisElectronsAuxDyn.ambiguityLink*\",\n",
    "    \"AnalysisMuonsAuxDyn.EnergyLoss\", \"AnalysisJetsAuxDyn.NNJvtPass\", \"AnalysisElectronsAuxDyn.topoetcone20_CloseByCorr\",\n",
    "    \"AnalysisElectronsAuxDyn.topoetcone20ptCorrection\", \"AnalysisElectronsAuxDyn.topoetcone20\",\n",
    "    \"AnalysisMuonsAuxDyn.ptvarcone30_Nonprompt_All_MaxWeightTTVA_pt500_CloseByCorr\",\n",
    "    \"AnalysisElectronsAuxDyn.DFCommonElectronsECIDSResult\", \"AnalysisElectronsAuxDyn.neflowisol20\",\n",
    "    \"AnalysisMuonsAuxDyn.ptvarcone30_Nonprompt_All_MaxWeightTTVA_pt500\", \"AnalysisMuonsAuxDyn.ptcone40\",\n",
    "    \"AnalysisMuonsAuxDyn.ptvarcone30_Nonprompt_All_MaxWeightTTVA_pt1000_CloseByCorr\",\n",
    "    \"AnalysisMuonsAuxDyn.ptvarcone30_Nonprompt_All_MaxWeightTTVA_pt1000\", \"AnalysisMuonsAuxDyn.ptvarcone40\",\n",
    "    \"AnalysisElectronsAuxDyn.f1\", \"AnalysisMuonsAuxDyn.ptcone20_Nonprompt_All_MaxWeightTTVA_pt500\",\n",
    "    \"PrimaryVerticesAuxDyn.vertexType\", \"AnalysisMuonsAuxDyn.ptvarcone30\", \"AnalysisMuonsAuxDyn.ptcone30\",\n",
    "    \"AnalysisMuonsAuxDyn.ptcone20_Nonprompt_All_MaxWeightTTVA_pt1000\",\n",
    "    \"AnalysisElectronsAuxDyn.ptvarcone30_Nonprompt_All_MaxWeightTTVALooseCone_pt500\", \"AnalysisMuonsAuxDyn.CaloLRLikelihood\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2a41d4e-22ea-4167-adc7-91d6114d829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for funcadl-uproot\n",
    "# funcadl_query = FuncADLQuery()\n",
    "# for b in BRANCH_LIST:\n",
    "#     funcadl_query = funcadl_query.Select(lambda e: {b: e[b]})\n",
    "\n",
    "# for atlasr22\n",
    "funcadl_query = FuncADLQueryPHYSLITE()\n",
    "funcadl_query = funcadl_query.Select(lambda e: {\n",
    "        \"evt\": e.EventInfo(\"EventInfo\"),\n",
    "        \"jet\": e.Jets(),\n",
    "    })\n",
    "funcadl_query = funcadl_query.Select(lambda ei: {\n",
    "            \"event_number\": ei.evt.eventNumber(),  # type: ignore\n",
    "            \"run_number\": ei.evt.runNumber(),  # type: ignore\n",
    "            \"jet_pt\": ei.jet.Select(lambda j: j.pt() / 1000),  # type: ignore\n",
    "            \"jet_eta\": ei.jet.Select(lambda j: j.eta()),  # type: ignore\n",
    "            \"jet_phi\": ei.jet.Select(lambda j: j.phi()),  # type: ignore\n",
    "            \"jet_m\": ei.jet.Select(lambda j: j.m()),  # type: ignore\n",
    "            \"jet_EnergyPerSampling\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_vfloat](\"EnergyPerSampling\")\n",
    "                ),\n",
    "            \"jet_SumPtTrkPt500\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_vfloat](\"SumPtTrkPt500\")\n",
    "                ),\n",
    "            \"jet_TrackWidthPt1000\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_vfloat](\"TrackWidthPt1000\")\n",
    "                ),\n",
    "            \"jet_NumTrkPt500\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_vint](\"NumTrkPt500\")\n",
    "                ),\n",
    "            \"jet_NumTrkPt1000\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_vint](\"NumTrkPt1000\")\n",
    "                ),\n",
    "            \"jet_SumPtChargedPFOPt500\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_vfloat](\"SumPtChargedPFOPt500\")\n",
    "                ),\n",
    "            \"jet_Timing\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_float](\"Timing\")\n",
    "                ),\n",
    "            \"jet_JetConstitScaleMomentum_eta\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_float](\"JetConstitScaleMomentum_eta\")\n",
    "                ),\n",
    "            \"jet_ActiveArea4vec_eta\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_float](\"ActiveArea4vec_eta\")\n",
    "                ),\n",
    "            \"jet_DetectorEta\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_float](\"DetectorEta\")\n",
    "                ),\n",
    "            \"jet_JetConstitScaleMomentum_phi\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_float](\"JetConstitScaleMomentum_phi\")\n",
    "                ),\n",
    "            \"jet_ActiveArea4vec_phi\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_float](\"ActiveArea4vec_phi\")\n",
    "                ),\n",
    "            \"jet_JetConstitScaleMomentum_m\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_float](\"JetConstitScaleMomentum_m\")\n",
    "                ),\n",
    "            \"jet_JetConstitScaleMomentum_pt\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_float](\"JetConstitScaleMomentum_pt\")\n",
    "                ),\n",
    "            \"jet_Width\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_float](\"Width\")\n",
    "                ),\n",
    "            \"jet_EMFrac\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_float](\"EMFrac\")\n",
    "                ),\n",
    "            \"jet_ActiveArea4vec_m\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_float](\"ActiveArea4vec_m\")\n",
    "                ),\n",
    "            \"jet_DFCommonJets_QGTagger_TracksWidth\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_float](\"DFCommonJets_QGTagger_TracksWidth\")\n",
    "                ),\n",
    "            \"jet_JVFCorr\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_float](\"JVFCorr\")\n",
    "                ),\n",
    "            \"jet_DFCommonJets_QGTagger_TracksC1\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_float](\"DFCommonJets_QGTagger_TracksC1\")\n",
    "                ),\n",
    "            \"jet_PSFrac\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_float](\"PSFrac\")\n",
    "                ),\n",
    "            \"jet_DFCommonJets_QGTagger_NTracks\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_int](\"DFCommonJets_QGTagger_NTracks\")\n",
    "                ),\n",
    "            \"jet_DFCommonJets_fJvt\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_float](\"DFCommonJets_fJvt\")\n",
    "                ),\n",
    "            \"jet_PartonTruthLabelID\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_int](\"PartonTruthLabelID\")\n",
    "                ),\n",
    "            \"jet_HadronConeExclExtendedTruthLabelID\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_int](\"HadronConeExclExtendedTruthLabelID\")\n",
    "                ),\n",
    "            \"jet_ConeTruthLabelID\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_int](\"ConeTruthLabelID\")\n",
    "                ),\n",
    "            \"jet_HadronConeExclTruthLabelID\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_int](\"HadronConeExclTruthLabelID\")\n",
    "                ),\n",
    "            \"jet_ActiveArea4vec_pt\":\n",
    "                ei.jet.Select(  # type: ignore\n",
    "                    lambda j: j.getAttribute[cpp_float](\"ActiveArea4vec_pt\")\n",
    "                ),\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "446cfacc-eb97-4119-b168-d17d500752a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileset summary\n",
      " - number of files: 30\n",
      "cannot determine total size / number of events when max_files_per_container is being used\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Returning code generators from cache\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Returning code generators from cache\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd89764cca041e2964a93e11b6ae8d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">ServiceX Transform </span><span style=\"color: #ffff00; text-decoration-color: #ffff00; font-weight: bold\">e140785e-e598-4b49-96dd-882bbe29e1c3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mServiceX Transform \u001b[0m\u001b[1;93me140785e-e598-4b49-96dd-882bbe29e1c3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transforms completed successfully\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Transforms completed successfully\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------\n",
    "# INPUT CONFIGURATION\n",
    "# -------------------\n",
    "# modify this to change how many files are being processed\n",
    "# top-level processes determine containers/DSIDs, which each have some number of files\n",
    "# full list is list(find_containers.container_dict.keys()) + [\"data15_13TeV\", \"data16_13TeV\", \"data17_13TeV\", \"data18_13TeV\"]\n",
    "\n",
    "PROCESSES_TO_USE = [\"ttbar\"]  # 6.7 TB\n",
    "# PROCESSES_TO_USE = [\"db\", \"zjets\", \"wjets\", \"ttV\", \"othertop\", \"ttbar\"]  # all simulation, 48.4 TB\n",
    "# PROCESSES_TO_USE = [\"db\", \"zjets\", \"wjets\", \"ttV\", \"othertop\", \"ttbar\", \"data15_13TeV\", \"data16_13TeV\", \"data17_13TeV\", \"data18_13TeV\"]  # 191 TB\n",
    "\n",
    "fileset = utils.get_fileset(PROCESSES_TO_USE, max_files_per_container=10, max_containers_per_dsid=None, max_dsid_per_process=None)\n",
    "ofileset = fileset\n",
    "# print(fileset)\n",
    "\n",
    "newfset = { _ : {} for _ in fileset }\n",
    "REMOTE_ACCESS = True\n",
    "PARQUET = False\n",
    "QUERYLANG = 'funcadl-xaod'\n",
    "\n",
    "if QUERYLANG == 'uproot':\n",
    "    Codegen = 'uproot-raw'\n",
    "    Query = UprootRawQuery({'treename': 'CollectionTree', 'filter_name': BRANCH_LIST})\n",
    "    ServiceX = 'testing4'\n",
    "    Tree = 'CollectionTree'\n",
    "elif QUERYLANG == 'funcadl-xaod':\n",
    "    Codegen = 'atlasr22'\n",
    "    Query = funcadl_query\n",
    "    ServiceX = 'main'\n",
    "    Tree = 'nominal'\n",
    "elif QUERYLANG == 'funcadl-uproot':\n",
    "    Codegen = 'uproot'\n",
    "    Query = funcadl_query\n",
    "    ServiceX = 'main'\n",
    "    Tree = 'CollectionTree'\n",
    "\n",
    "spec = ServiceXSpec(\n",
    "    General=General(\n",
    "        ServiceX=ServiceX,\n",
    "        Codegen=Codegen,\n",
    "        OutputFormat=('parquet' if PARQUET else 'root-file'),\n",
    "        Delivery=('SignedURLs' if REMOTE_ACCESS else 'LocalCache'),\n",
    "    ),\n",
    "    Sample=[Sample(Name=process,\n",
    "                     XRootDFiles=[strip_xcache(_) for _ in process_vals['files'].keys()],\n",
    "                     Tree=Tree,\n",
    "                     Query=Query,\n",
    "                     IgnoreLocalCache=True,\n",
    "                   # Codegen='atlasr22',\n",
    "                    )\n",
    "           for process, process_vals in fileset.items()],\n",
    ")\n",
    "data = deliver(spec)\n",
    "for process, d in data.items():\n",
    "    if PARQUET:\n",
    "        newfset[process]['files'] = [_ for _ in d]\n",
    "    else:\n",
    "        if QUERYLANG == 'funcadl-xaod':\n",
    "            newfset[process]['files'] = {_: 'atlas_xaod_tree' for _ in d}\n",
    "        else:\n",
    "            newfset[process]['files'] = {_: 'CollectionTree' for _ in d}\n",
    "fileset = newfset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff312282-a87b-4394-aff4-6acc12d27c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files at MWT2: 30, elsewhere: 0\n"
     ]
    }
   ],
   "source": [
    "# check for files not yet replicated to MWT2 - kind of beside the point\n",
    "files_at_mwt2 = 0\n",
    "files_elsewhere = 0\n",
    "for process in ofileset.keys():\n",
    "    for file in ofileset[process][\"files\"]:\n",
    "        if \"mwt2\" in file:\n",
    "            files_at_mwt2 += 1\n",
    "        else:\n",
    "            files_elsewhere += 1\n",
    "\n",
    "print(f\"files at MWT2: {files_at_mwt2}, elsewhere: {files_elsewhere}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a38efe4-8024-422c-ba42-12bd3a3b44cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def raw_materialize_branches(events, remap=True):\n",
    "    num_events = ak.num(events, axis=0)  # track number of events\n",
    "\n",
    "    # this will read around 25% of data files\n",
    "    # materialize branches, just derive integers from them that will be aggregated to avoid memory issues\n",
    "    _counter = 0\n",
    "    for branch in BRANCH_LIST:\n",
    "        if remap:\n",
    "            obj_name, obj_prop = branch.split(\".\")\n",
    "            obj_name = obj_name.replace(\"Analysis\", \"\").replace(\"AuxDyn\", \"\")\n",
    "            if \"Link\" not in obj_prop:\n",
    "                branch_data = events[obj_name, obj_prop]\n",
    "            else:\n",
    "                branch_data = events[obj_name, obj_prop][\"m_persIndex\"]\n",
    "        else:\n",
    "            obj_name = branch.replace('*', '')\n",
    "            if \"Link\" not in obj_name:\n",
    "                branch_data = events[obj_name]\n",
    "            # else:\n",
    "            #     branch_data = events[f'{obj_name}.m_persIndex']           \n",
    "                _counter += ak.count_nonzero(branch_data)\n",
    "\n",
    "    return {\"nevts\": num_events, \"_counter\": _counter}\n",
    "\n",
    "def funcadl_materialize_branches(data, remap=True):\n",
    "    num_events = ak.num(data, axis=0)  # track number of events\n",
    "    total_count = 0\n",
    "    for field in data.fields:\n",
    "        logging.debug(f\"Counting field {field}\")\n",
    "        if str(data[field].type.content).startswith(\"var\"):\n",
    "            count = ak.count_nonzero(data[field], axis=-1)\n",
    "            for _ in range(count.ndim - 1):  # type: ignore\n",
    "                count = ak.count_nonzero(count)\n",
    "\n",
    "            total_count = total_count + count  # type: ignore\n",
    "        else:\n",
    "            # We get a not implemented error when we try to do this\n",
    "            # on leaves like run-number or event-number (e.g. scalars)\n",
    "            # Maybe we should just be adding a 1. :-)\n",
    "            logging.info(f\"Field {field} is not a scalar field. Skipping count.\")\n",
    "\n",
    "    # total_count = ak.count_nonzero(total_count, axis=0)\n",
    "    return {\"nevts\": num_events, \"_counter\": total_count}\n",
    "\n",
    "if QUERYLANG == 'funcadl-xaod':\n",
    "    materialize_branches = funcadl_materialize_branches\n",
    "else:\n",
    "    materialize_branches = raw_materialize_branches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31f12d0-353e-4c3b-8bcd-83a6956eed26",
   "metadata": {},
   "source": [
    "# following cells are for ROOT output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed1ecc41-0a72-44ec-a8b8-654286a02196",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.9 s, sys: 2.08 s, total: 19 s\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# from coffea.dataset_tools.preprocess import _normalize_file_info\n",
    "# # print(fileset)\n",
    "# print(ak.from_iter(_normalize_file_info(fileset['ttbar']['files'])))\n",
    "# pre-process\n",
    "# samples, report = dataset_tools.preprocess(fileset, skip_bad_files=True, uproot_options={\"allow_read_errors_with_report\": True})\n",
    "samples, report = dataset_tools.preprocess(fileset, skip_bad_files=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7cf89ae-569f-4191-963d-d0e122eaf7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find issues where access did not work\n",
    "for process in report:\n",
    "    for k, v in report[process][\"files\"].items():\n",
    "        if v[\"steps\"] is None:\n",
    "            print(f\"could not read {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15835a57-1182-4efb-8306-07f36af7a5b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 s, sys: 317 ms, total: 2.32 s\n",
      "Wall time: 3.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create the task graph\n",
    "# filter_name seems to not do anything here in terms of performance\n",
    "filter_name = lambda name: name in BRANCH_LIST\n",
    "tasks = dataset_tools.apply_to_fileset(materialize_branches,\n",
    "                                       samples,\n",
    "                                       uproot_options={\"allow_read_errors_with_report\": (OSError, TypeError), \"filter_name\": filter_name},\n",
    "                                       schemaclass=PHYSLITESchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b6dfb17-6806-46c8-aa59-cd475e40cf64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time spent in uproot reading data: 33.19 s\n",
      "wall time: 8.90s\n",
      "CPU times: user 5.71 s, sys: 768 ms, total: 6.48 s\n",
      "Wall time: 8.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# execute task graph\n",
    "t0 = time.perf_counter()\n",
    "with performance_report(filename=\"dask-report.html\"):\n",
    "    ((out, report),) = dask.compute(tasks)  # feels strange that this is a tuple-of-tuple\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "print(f\"total time spent in uproot reading data: {ak.sum([v['duration'] for v in report.values()]):.2f} s\")\n",
    "print(f\"wall time: {t1-t0:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb47e9e5-57ea-4385-b8f8-b2a22ded030e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: {'ttbar': {'nevts': 650000, '_counter': 0}}\n",
      "\n",
      "performance metrics:\n",
      " - event rate: 72.99 kHz\n",
      " - read 0.84 MB in 8.90 s -> 0.75 Mbps (need to scale by x266434 to reach 200 Gbps)\n"
     ]
    }
   ],
   "source": [
    "print(f\"output: {out}\")\n",
    "\n",
    "print(\"\\nperformance metrics:\")\n",
    "event_rate = sum([out[process][\"nevts\"] for process in out.keys()]) / (t1-t0)\n",
    "print(f\" - event rate: {event_rate / 1_000:.2f} kHz\")\n",
    "\n",
    "# need uproot>=5.3.2 to get these useful performance stats\n",
    "num_bytes = ak.sum([report[process][\"performance_counters\"][\"num_requested_bytes\"] for process in out.keys()])\n",
    "read_MB = num_bytes / 1_000**2\n",
    "rate_Mbs = read_MB / (t1-t0)\n",
    "print(f\" - read {read_MB:.2f} MB in {t1-t0:.2f} s -> {rate_Mbs*8:.2f} Mbps (need to scale by x{200/8/rate_Mbs*1000:.0f} to reach 200 Gbps)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8da90743-8045-42f3-a59c-12c7ff9f8b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report problematic files that caused exceptions\n",
    "for process in report.keys():\n",
    "    for i_file in range(len(report[process].exception)):\n",
    "        file_report = report[process][i_file]\n",
    "        if file_report.exception is not None:\n",
    "            print(file_report.args[0].strip(\"\\'\"))\n",
    "            print(file_report.message + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51fb1ab6-0be4-4b99-942a-c1b53eda5639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check that the right colums are being touched\n",
    "# dak.report_necessary_columns(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25225440-d57c-49e7-b48e-43fe5362327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if issues with files exist, paste in path and reproduce\n",
    "# fname = \"root://192.170.240.146:1094//root://fax.mwt2.org:1094//pnfs/uchicago.edu/atlaslocalgroupdisk/rucio/mc20_13TeV/59/28/DAOD_PHYSLITE.37231868._000040.pool.root.1\"\n",
    "# treename = \"CollectionTree\"\n",
    "# events = NanoEventsFactory.from_root({fname: treename}, schemaclass=PHYSLITESchema).events()\n",
    "# task = materialize_branches(events)\n",
    "# task[\"_counter\"].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f76a4b-fb8b-4e39-b839-a2962e225d21",
   "metadata": {},
   "source": [
    "# following cells are for parquet output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ca1489d-5c40-45d9-bf77-75f91a26beca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty urlpath sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# This will fail for now on uproot output due to https://github.com/dask-contrib/dask-awkward/issues/501\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# events = NanoEventsFactory.from_parquet(fileset['ttbar']['files'][0], schemaclass=PHYSLITESchema)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# task = materialize_branches(events)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# task[\"_counter\"].compute()\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(fileset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mttbar\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiles\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mdak\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mttbar\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfiles\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbehavior\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPHYSLITESchema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbehavior\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# filter_name = lambda name: name in BRANCH_LIST\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# ds.map_partitions(materialize_branches)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m task \u001b[38;5;241m=\u001b[39m materialize_branches(ds, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/code/onyisi/python3.11-coffea2024-servicex3/lib64/python3.11/site-packages/dask_awkward/lib/io/parquet.py:314\u001b[0m, in \u001b[0;36mfrom_parquet\u001b[0;34m(path, columns, max_gap, max_block, footer_sample_size, generate_bitmasks, highlevel, behavior, attrs, ignore_metadata, scan_files, split_row_groups, storage_options, report)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m highlevel:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdask-awkward only supports highlevel=True\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 314\u001b[0m fs, token, paths \u001b[38;5;241m=\u001b[39m \u001b[43mget_fs_token_paths\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom-parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m token \u001b[38;5;241m=\u001b[39m tokenize(\n\u001b[1;32m    321\u001b[0m     token,\n\u001b[1;32m    322\u001b[0m     paths,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    333\u001b[0m     attrs,\n\u001b[1;32m    334\u001b[0m )\n",
      "File \u001b[0;32m/code/onyisi/python3.11-coffea2024-servicex3/lib64/python3.11/site-packages/fsspec/core.py:617\u001b[0m, in \u001b[0;36mget_fs_token_paths\u001b[0;34m(urlpath, mode, num, name_function, storage_options, protocol, expand)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(urlpath, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mset\u001b[39m)):\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m urlpath:\n\u001b[0;32m--> 617\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty urlpath sequence\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    618\u001b[0m     urlpath0 \u001b[38;5;241m=\u001b[39m stringify_path(\u001b[38;5;28mlist\u001b[39m(urlpath)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: empty urlpath sequence"
     ]
    }
   ],
   "source": [
    "# This will fail for now on uproot output due to https://github.com/dask-contrib/dask-awkward/issues/501\n",
    "\n",
    "# events = NanoEventsFactory.from_parquet(fileset['ttbar']['files'][0], schemaclass=PHYSLITESchema)\n",
    "# task = materialize_branches(events)\n",
    "# task[\"_counter\"].compute()\n",
    "print(fileset['ttbar']['files'])\n",
    "ds = dak.from_parquet(fileset['ttbar']['files'], behavior=PHYSLITESchema.behavior())\n",
    "# filter_name = lambda name: name in BRANCH_LIST\n",
    "# ds.map_partitions(materialize_branches)\n",
    "task = materialize_branches(ds, False)\n",
    "task[\"_counter\"].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d2b193-430c-4bad-bedf-49e7b853af65",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"root://fax.mwt2.org:1094//pnfs/uchicago.edu/atlaslocalgroupdisk/rucio/mc20_13TeV/59/28/DAOD_PHYSLITE.37231868._000040.pool.root.1\"\n",
    "treename = \"CollectionTree\"\n",
    "events = NanoEventsFactory.from_root({fname: treename}, schemaclass=PHYSLITESchema).events()\n",
    "task = materialize_branches(events)\n",
    "task[\"_counter\"].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b556d3e-5350-4863-9fc0-492247b1c26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ttbar': []}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d02bc2d-d277-461a-8298-91e89979aa63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "all,-jupytext.text_representation.jupytext_version,-language_info.version"
  },
  "kernelspec": {
   "display_name": "python3.11-coffea2024-servicex3",
   "language": "python",
   "name": "python3.11-coffea2024-servicex3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
