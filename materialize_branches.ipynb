{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "180f4d32-e5c4-42f9-84e8-430034493a55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awkward: 2.6.3\n",
      "dask-awkward: 2024.3.0\n",
      "uproot: 5.3.2\n",
      "hist: 2.7.2\n",
      "coffea: 2024.4.1\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import awkward as ak\n",
    "import dask\n",
    "import dask_awkward as dak\n",
    "import hist.dask\n",
    "import coffea\n",
    "import numpy as np\n",
    "import uproot\n",
    "from dask.distributed import Client\n",
    "\n",
    "from coffea.nanoevents import NanoEventsFactory, PHYSLITESchema\n",
    "from coffea import dataset_tools\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from input_files import utils\n",
    "\n",
    "from dask.distributed import LocalCluster, Client, progress, performance_report\n",
    "\n",
    "# local: single thread, single worker\n",
    "# cluster = LocalCluster(n_workers=1, processes=False, threads_per_worker=1)\n",
    "# client = Client(cluster)\n",
    "\n",
    "# for UChicago\n",
    "client = Client(\"tcp://dask-alheld-2ec78772-d.af-jupyter:8786\")  # update this to point to your own client!\n",
    "\n",
    "print(f\"awkward: {ak.__version__}\")\n",
    "print(f\"dask-awkward: {dak.__version__}\")\n",
    "print(f\"uproot: {uproot.__version__}\")\n",
    "print(f\"hist: {hist.__version__}\")\n",
    "print(f\"coffea: {coffea.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef7dd8d-68e5-43fa-b8bf-5d8f972520c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileset summary\n",
      " - number of files: 30\n",
      "cannot determine total size / number of events when max_files_per_container is being used\n"
     ]
    }
   ],
   "source": [
    "# -------------------\n",
    "# INPUT CONFIGURATION\n",
    "# -------------------\n",
    "# modify this to change how many files are being processed\n",
    "# top-level processes determine containers/DSIDs, which each have some number of files\n",
    "# full list is list(find_containers.container_dict.keys()) + [\"data15_13TeV\", \"data16_13TeV\", \"data17_13TeV\", \"data18_13TeV\"]\n",
    "\n",
    "PROCESSES_TO_USE = [\"ttbar\"]  # 6.7 TB\n",
    "# PROCESSES_TO_USE = [\"db\", \"zjets\", \"wjets\", \"ttV\", \"othertop\", \"ttbar\"]  # all simulation, 48.4 TB\n",
    "# PROCESSES_TO_USE = [\"db\", \"zjets\", \"wjets\", \"ttV\", \"othertop\", \"ttbar\", \"data15_13TeV\", \"data16_13TeV\", \"data17_13TeV\", \"data18_13TeV\"]  # 191 TB\n",
    "\n",
    "fileset = utils.get_fileset(PROCESSES_TO_USE, max_files_per_container=10, max_containers_per_dsid=None, max_dsid_per_process=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff312282-a87b-4394-aff4-6acc12d27c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files at MWT2: 30, elsewhere: 0\n"
     ]
    }
   ],
   "source": [
    "# check for files not yet replicated to MWT2\n",
    "files_at_mwt2 = 0\n",
    "files_elsewhere = 0\n",
    "for process in fileset.keys():\n",
    "    for file in fileset[process][\"files\"]:\n",
    "        if \"mwt2\" in file:\n",
    "            files_at_mwt2 += 1\n",
    "        else:\n",
    "            files_elsewhere += 1\n",
    "\n",
    "print(f\"files at MWT2: {files_at_mwt2}, elsewhere: {files_elsewhere}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a38efe4-8024-422c-ba42-12bd3a3b44cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BRANCH_LIST = [\n",
    "    \"AnalysisJetsAuxDyn.pt\", \"AnalysisJetsAuxDyn.eta\", \"AnalysisJetsAuxDyn.phi\", \"AnalysisJetsAuxDyn.m\",\n",
    "    \"AnalysisElectronsAuxDyn.pt\", \"AnalysisElectronsAuxDyn.eta\", \"AnalysisElectronsAuxDyn.phi\",\n",
    "    \"AnalysisElectronsAuxDyn.m\", \"AnalysisMuonsAuxDyn.pt\", \"AnalysisMuonsAuxDyn.eta\",\n",
    "    \"AnalysisMuonsAuxDyn.phi\", \"AnalysisJetsAuxDyn.EnergyPerSampling\", \"AnalysisJetsAuxDyn.SumPtTrkPt500\",\n",
    "    \"AnalysisJetsAuxDyn.TrackWidthPt1000\", \"PrimaryVerticesAuxDyn.z\", \"PrimaryVerticesAuxDyn.x\",\n",
    "    \"PrimaryVerticesAuxDyn.y\", \"AnalysisJetsAuxDyn.NumTrkPt500\", \"AnalysisJetsAuxDyn.NumTrkPt1000\",\n",
    "    \"AnalysisJetsAuxDyn.SumPtChargedPFOPt500\", \"AnalysisJetsAuxDyn.Timing\",\n",
    "    \"AnalysisJetsAuxDyn.JetConstitScaleMomentum_eta\", \"AnalysisJetsAuxDyn.ActiveArea4vec_eta\",\n",
    "    \"AnalysisJetsAuxDyn.DetectorEta\", \"AnalysisJetsAuxDyn.JetConstitScaleMomentum_phi\",\n",
    "    \"AnalysisJetsAuxDyn.ActiveArea4vec_phi\", \"AnalysisJetsAuxDyn.JetConstitScaleMomentum_m\",\n",
    "    \"AnalysisJetsAuxDyn.JetConstitScaleMomentum_pt\", \"AnalysisJetsAuxDyn.EMFrac\",\n",
    "    \"AnalysisJetsAuxDyn.Width\", \"AnalysisJetsAuxDyn.ActiveArea4vec_m\", \"AnalysisJetsAuxDyn.ActiveArea4vec_pt\",\n",
    "    \"AnalysisJetsAuxDyn.DFCommonJets_QGTagger_TracksWidth\", \"AnalysisJetsAuxDyn.PSFrac\",\n",
    "    \"AnalysisJetsAuxDyn.JVFCorr\", \"AnalysisJetsAuxDyn.DFCommonJets_QGTagger_TracksC1\",\n",
    "    \"AnalysisJetsAuxDyn.DFCommonJets_fJvt\", \"AnalysisJetsAuxDyn.DFCommonJets_QGTagger_NTracks\",\n",
    "    \"AnalysisJetsAuxDyn.GhostMuonSegmentCount\", \"AnalysisMuonsAuxDyn.muonSegmentLinks\",\n",
    "    \"AnalysisMuonsAuxDyn.msOnlyExtrapolatedMuonSpectrometerTrackParticleLink\",\n",
    "    \"AnalysisMuonsAuxDyn.extrapolatedMuonSpectrometerTrackParticleLink\",\n",
    "    \"AnalysisMuonsAuxDyn.inDetTrackParticleLink\", \"AnalysisMuonsAuxDyn.muonSpectrometerTrackParticleLink\",\n",
    "    \"AnalysisMuonsAuxDyn.momentumBalanceSignificance\", \"AnalysisMuonsAuxDyn.topoetcone20_CloseByCorr\",\n",
    "    \"AnalysisMuonsAuxDyn.scatteringCurvatureSignificance\", \"AnalysisMuonsAuxDyn.scatteringNeighbourSignificance\",\n",
    "    \"AnalysisMuonsAuxDyn.neflowisol20_CloseByCorr\", \"AnalysisMuonsAuxDyn.topoetcone20\",\n",
    "    \"AnalysisMuonsAuxDyn.topoetcone30\", \"AnalysisMuonsAuxDyn.topoetcone40\", \"AnalysisMuonsAuxDyn.neflowisol20\",\n",
    "    \"AnalysisMuonsAuxDyn.segmentDeltaEta\", \"AnalysisMuonsAuxDyn.DFCommonJetDr\",\n",
    "    \"AnalysisMuonsAuxDyn.combinedTrackParticleLink\", \"AnalysisMuonsAuxDyn.InnerDetectorPt\",\n",
    "    \"AnalysisMuonsAuxDyn.MuonSpectrometerPt\", \"AnalysisMuonsAuxDyn.clusterLink\",\n",
    "    \"AnalysisMuonsAuxDyn.spectrometerFieldIntegral\", \"AnalysisElectronsAuxDyn.ambiguityLink\",\n",
    "    \"AnalysisMuonsAuxDyn.EnergyLoss\", \"AnalysisJetsAuxDyn.NNJvtPass\", \"AnalysisElectronsAuxDyn.topoetcone20_CloseByCorr\",\n",
    "    \"AnalysisElectronsAuxDyn.topoetcone20ptCorrection\", \"AnalysisElectronsAuxDyn.topoetcone20\",\n",
    "    \"AnalysisMuonsAuxDyn.ptvarcone30_Nonprompt_All_MaxWeightTTVA_pt500_CloseByCorr\",\n",
    "    \"AnalysisElectronsAuxDyn.DFCommonElectronsECIDSResult\", \"AnalysisElectronsAuxDyn.neflowisol20\",\n",
    "    \"AnalysisMuonsAuxDyn.ptvarcone30_Nonprompt_All_MaxWeightTTVA_pt500\", \"AnalysisMuonsAuxDyn.ptcone40\",\n",
    "    \"AnalysisMuonsAuxDyn.ptvarcone30_Nonprompt_All_MaxWeightTTVA_pt1000_CloseByCorr\",\n",
    "    \"AnalysisMuonsAuxDyn.ptvarcone30_Nonprompt_All_MaxWeightTTVA_pt1000\", \"AnalysisMuonsAuxDyn.ptvarcone40\",\n",
    "    \"AnalysisElectronsAuxDyn.f1\", \"AnalysisMuonsAuxDyn.ptcone20_Nonprompt_All_MaxWeightTTVA_pt500\",\n",
    "    \"PrimaryVerticesAuxDyn.vertexType\", \"AnalysisMuonsAuxDyn.ptvarcone30\", \"AnalysisMuonsAuxDyn.ptcone30\",\n",
    "    \"AnalysisMuonsAuxDyn.ptcone20_Nonprompt_All_MaxWeightTTVA_pt1000\",\n",
    "    \"AnalysisElectronsAuxDyn.ptvarcone30_Nonprompt_All_MaxWeightTTVALooseCone_pt500\", \"AnalysisMuonsAuxDyn.CaloLRLikelihood\"\n",
    "]\n",
    "\n",
    "def materialize_branches(events):\n",
    "    num_events = ak.num(events, axis=0)  # track number of events\n",
    "\n",
    "    # this will read around 25% of data files\n",
    "    # materialize branches, just derive integers from them that will be aggregated to avoid memory issues\n",
    "    _counter = 0\n",
    "    for branch in BRANCH_LIST:\n",
    "        obj_name, obj_prop = branch.split(\".\")\n",
    "        obj_name = obj_name.replace(\"Analysis\", \"\").replace(\"AuxDyn\", \"\")\n",
    "        if \"Link\" not in obj_prop:\n",
    "            branch_data = events[obj_name, obj_prop]\n",
    "        else:\n",
    "            branch_data = events[obj_name, obj_prop][\"m_persIndex\"]\n",
    "\n",
    "        _counter_to_add = ak.count_nonzero(branch_data, axis=-1)  # reduce innermost\n",
    "\n",
    "        # reduce >2-dimensional (per event) branches further\n",
    "        for _ in range(_counter_to_add.ndim - 1):\n",
    "            _counter_to_add = ak.count_nonzero(_counter_to_add, axis=-1)\n",
    "\n",
    "        _counter = _counter + _counter_to_add  # sum 1-dim array built from new branch\n",
    "\n",
    "    _counter = ak.count_nonzero(_counter, axis=0)  # reduce to int\n",
    "\n",
    "    return {\"nevts\": num_events, \"_counter\": _counter}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed1ecc41-0a72-44ec-a8b8-654286a02196",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 221 ms, sys: 59.7 ms, total: 280 ms\n",
      "Wall time: 32.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# pre-process\n",
    "with performance_report(filename=\"dask-report-preprocess.html\"):\n",
    "    samples, report = dataset_tools.preprocess(fileset, skip_bad_files=True, uproot_options={\"allow_read_errors_with_report\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7cf89ae-569f-4191-963d-d0e122eaf7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find issues where access did not work\n",
    "for process in report:\n",
    "    for k, v in report[process][\"files\"].items():\n",
    "        if v[\"steps\"] is None:\n",
    "            print(f\"could not read {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15835a57-1182-4efb-8306-07f36af7a5b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.49 s, sys: 96.2 ms, total: 3.59 s\n",
      "Wall time: 3.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create the task graph\n",
    "# filter_name seems to not do anything here in terms of performance\n",
    "filter_name = lambda name: name in BRANCH_LIST\n",
    "tasks = dataset_tools.apply_to_fileset(materialize_branches,\n",
    "                                       samples,\n",
    "                                       uproot_options={\"allow_read_errors_with_report\": (OSError, TypeError), \"filter_name\": filter_name},\n",
    "                                       schemaclass=PHYSLITESchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b6dfb17-6806-46c8-aa59-cd475e40cf64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time spent in uproot reading data: 360.42 s\n",
      "wall time: 24.95s\n",
      "CPU times: user 563 ms, sys: 18.2 ms, total: 581 ms\n",
      "Wall time: 24.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# execute task graph\n",
    "t0 = time.perf_counter()\n",
    "with performance_report(filename=\"dask-report-compute.html\"):\n",
    "    ((out, report),) = dask.compute(tasks)  # feels strange that this is a tuple-of-tuple\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "print(f\"total time spent in uproot reading data: {ak.sum([v['duration'] for v in report.values()]):.2f} s\")\n",
    "print(f\"wall time: {t1-t0:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb47e9e5-57ea-4385-b8f8-b2a22ded030e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: {'ttbar': {'nevts': 710000, '_counter': 710000}}\n",
      "\n",
      "performance metrics:\n",
      " - event rate: 28.46 kHz\n",
      " - read 1603.23 MB in 24.95 s -> 514.15 Mbps (need to scale by x389 to reach 200 Gbps)\n"
     ]
    }
   ],
   "source": [
    "print(f\"output: {out}\")\n",
    "\n",
    "print(\"\\nperformance metrics:\")\n",
    "event_rate = sum([out[process][\"nevts\"] for process in out.keys()]) / (t1-t0)\n",
    "print(f\" - event rate: {event_rate / 1_000:.2f} kHz\")\n",
    "\n",
    "# need uproot>=5.3.2 to get these useful performance stats\n",
    "num_bytes = ak.sum([report[process][\"performance_counters\"][\"num_requested_bytes\"] for process in out.keys()])\n",
    "read_MB = num_bytes / 1_000**2\n",
    "rate_Mbs = read_MB / (t1-t0)\n",
    "print(f\" - read {read_MB:.2f} MB in {t1-t0:.2f} s -> {rate_Mbs*8:.2f} Mbps (need to scale by x{200/8/rate_Mbs*1000:.0f} to reach 200 Gbps)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8da90743-8045-42f3-a59c-12c7ff9f8b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report problematic files that caused exceptions\n",
    "for process in report.keys():\n",
    "    for i_file in range(len(report[process].exception)):\n",
    "        file_report = report[process][i_file]\n",
    "        if file_report.exception is not None:\n",
    "            print(file_report.args[0].strip(\"\\'\"))\n",
    "            print(file_report.message + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51fb1ab6-0be4-4b99-942a-c1b53eda5639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check that the right colums are being touched\n",
    "# dak.report_necessary_columns(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25225440-d57c-49e7-b48e-43fe5362327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if issues with files exist, paste in path and reproduce\n",
    "# fname = \"root://192.170.240.143//root://fax.mwt2.org:1094//pnfs/uchicago.edu/atlaslocalgroupdisk/rucio/mc20_13TeV/6e/cf/DAOD_PHYSLITE.37230006._000001.pool.root.1\"\n",
    "# treename = \"CollectionTree\"\n",
    "# events = NanoEventsFactory.from_root({fname: treename}, schemaclass=PHYSLITESchema).events()\n",
    "# task = materialize_branches(events)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "all,-jupytext.text_representation.jupytext_version,-language_info.version"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
