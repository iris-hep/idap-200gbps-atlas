{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "180f4d32-e5c4-42f9-84e8-430034493a55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awkward: 2.6.2\n",
      "dask-awkward: 2024.3.0\n",
      "uproot: 5.3.2\n",
      "hist: 2.7.2\n",
      "coffea: 2024.3.0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import awkward as ak\n",
    "import dask\n",
    "import dask_awkward as dak\n",
    "import hist.dask\n",
    "import coffea\n",
    "import numpy as np\n",
    "import uproot\n",
    "from dask.distributed import Client\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.style.use(\"ggplot\")\n",
    "\n",
    "from coffea.nanoevents import NanoEventsFactory, PHYSLITESchema\n",
    "from coffea import dataset_tools\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from dask.distributed import LocalCluster, Client, progress, performance_report\n",
    "\n",
    "# local: single thread, single worker\n",
    "# cluster = LocalCluster(n_workers=1, processes=False, threads_per_worker=1)\n",
    "# client = Client(cluster)\n",
    "\n",
    "# for UChicago\n",
    "client = Client(\"tcp://dask-alheld-35a6011e-d.af-jupyter:8786\")\n",
    "\n",
    "print(f\"awkward: {ak.__version__}\")\n",
    "print(f\"dask-awkward: {dak.__version__}\")\n",
    "print(f\"uproot: {uproot.__version__}\")\n",
    "print(f\"hist: {hist.__version__}\")\n",
    "print(f\"coffea: {coffea.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dc48bd-585e-4c95-848b-3a59dc920f51",
   "metadata": {},
   "source": [
    "### interactive coffea for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d68e654e-0987-4bc6-865d-273c983e932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname = \"/data/alheld/200gbps-atlas/data18_13TeV.periodAllYear.physics_Main.PhysCont.DAOD_PHYSLITE.grp18_v01_p6026/DAOD_PHYSLITE.37021624._000036.pool.root.1\"\n",
    "# treename = \"CollectionTree\"\n",
    "# events = NanoEventsFactory.from_root({fname: treename}, schemaclass=PHYSLITESchema).events()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208ff780-6dcb-4448-89de-0f1ac6a1b0a0",
   "metadata": {},
   "source": [
    "### distributed coffea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a38efe4-8024-422c-ba42-12bd3a3b44cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def materialize_branches(events):\n",
    "    # track number of events\n",
    "    num_events = ak.num(events, axis=0)\n",
    "\n",
    "    # this will read around 25% of data files\n",
    "    # materialize branches, just derive integers from them that will be aggregated to avoid memory issues\n",
    "    _counter = 0\n",
    "    _counter += ak.count_nonzero(events.Jets.pt)\n",
    "    _counter += ak.count_nonzero(events.Jets.eta)\n",
    "    _counter += ak.count_nonzero(events.Jets.phi)\n",
    "    _counter += ak.count_nonzero(events.Jets.m)\n",
    "    _counter += ak.count_nonzero(events.Electrons.pt)\n",
    "    _counter += ak.count_nonzero(events.Electrons.eta)\n",
    "    _counter += ak.count_nonzero(events.Electrons.phi)\n",
    "    _counter += ak.count_nonzero(events.Electrons.m)\n",
    "    _counter += ak.count_nonzero(events.Muons.pt)\n",
    "    _counter += ak.count_nonzero(events.Muons.eta)\n",
    "    _counter += ak.count_nonzero(events.Muons.phi)\n",
    "    _counter += ak.count_nonzero(events.Jets.EnergyPerSampling)\n",
    "    _counter += ak.count_nonzero(events.Jets.SumPtTrkPt500)\n",
    "    _counter += ak.count_nonzero(events.Jets.TrackWidthPt1000)\n",
    "    _counter += ak.count_nonzero(events.PrimaryVertices.z)\n",
    "    _counter += ak.count_nonzero(events.PrimaryVertices.x)\n",
    "    _counter += ak.count_nonzero(events.PrimaryVertices.y)\n",
    "    _counter += ak.count_nonzero(events.Jets.NumTrkPt500)\n",
    "    _counter += ak.count_nonzero(events.Jets.NumTrkPt1000)\n",
    "    _counter += ak.count_nonzero(events.Jets.SumPtChargedPFOPt500)\n",
    "    _counter += ak.count_nonzero(events.Jets.Timing)\n",
    "    _counter += ak.count_nonzero(events.Jets.JetConstitScaleMomentum_eta)\n",
    "    _counter += ak.count_nonzero(events.Jets.ActiveArea4vec_eta)\n",
    "    _counter += ak.count_nonzero(events.Jets.DetectorEta)\n",
    "    _counter += ak.count_nonzero(events.Jets.JetConstitScaleMomentum_phi)\n",
    "    _counter += ak.count_nonzero(events.Jets.ActiveArea4vec_phi)\n",
    "    _counter += ak.count_nonzero(events.Jets.JetConstitScaleMomentum_m)\n",
    "    _counter += ak.count_nonzero(events.Jets.JetConstitScaleMomentum_pt)\n",
    "    _counter += ak.count_nonzero(events.Jets.EMFrac)\n",
    "    _counter += ak.count_nonzero(events.Jets.Width)\n",
    "    _counter += ak.count_nonzero(events.Jets.ActiveArea4vec_m)\n",
    "    _counter += ak.count_nonzero(events.Jets.ActiveArea4vec_pt)\n",
    "    _counter += ak.count_nonzero(events.Jets.DFCommonJets_QGTagger_TracksWidth)\n",
    "    _counter += ak.count_nonzero(events.Jets.PSFrac)\n",
    "    _counter += ak.count_nonzero(events.Jets.JVFCorr)\n",
    "    _counter += ak.count_nonzero(events.Jets.DFCommonJets_QGTagger_TracksC1)\n",
    "    _counter += ak.count_nonzero(events.Jets.DFCommonJets_fJvt)\n",
    "    _counter += ak.count_nonzero(events.Jets.DFCommonJets_QGTagger_NTracks)\n",
    "    _counter += ak.count_nonzero(events.Jets.GhostMuonSegmentCount)\n",
    "    _counter += ak.count_nonzero(events.Muons.muonSegmentLinks['m_persIndex'])\n",
    "    _counter += ak.count_nonzero(events.Muons.msOnlyExtrapolatedMuonSpectrometerTrackParticleLink['m_persIndex'])\n",
    "    _counter += ak.count_nonzero(events.Muons.extrapolatedMuonSpectrometerTrackParticleLink['m_persIndex'])\n",
    "    _counter += ak.count_nonzero(events.Muons.inDetTrackParticleLink['m_persIndex'])\n",
    "    _counter += ak.count_nonzero(events.Muons.muonSpectrometerTrackParticleLink['m_persIndex'])\n",
    "    _counter += ak.count_nonzero(events.Muons.momentumBalanceSignificance)\n",
    "    _counter += ak.count_nonzero(events.Muons.topoetcone20_CloseByCorr)\n",
    "    _counter += ak.count_nonzero(events.Muons.scatteringCurvatureSignificance)\n",
    "    _counter += ak.count_nonzero(events.Muons.scatteringNeighbourSignificance)\n",
    "    _counter += ak.count_nonzero(events.Muons.neflowisol20_CloseByCorr)\n",
    "    _counter += ak.count_nonzero(events.Muons.topoetcone20)\n",
    "    _counter += ak.count_nonzero(events.Muons.topoetcone30)\n",
    "    _counter += ak.count_nonzero(events.Muons.topoetcone40)\n",
    "    _counter += ak.count_nonzero(events.Muons.neflowisol20)\n",
    "    _counter += ak.count_nonzero(events.Muons.segmentDeltaEta)\n",
    "    _counter += ak.count_nonzero(events.Muons.DFCommonJetDr)\n",
    "    _counter += ak.count_nonzero(events.Muons.combinedTrackParticleLink['m_persIndex'])\n",
    "    _counter += ak.count_nonzero(events.Muons.InnerDetectorPt)\n",
    "    _counter += ak.count_nonzero(events.Muons.MuonSpectrometerPt)\n",
    "    _counter += ak.count_nonzero(events.Muons.clusterLink['m_persIndex'])\n",
    "    _counter += ak.count_nonzero(events.Muons.spectrometerFieldIntegral)\n",
    "    _counter += ak.count_nonzero(events.Electrons.ambiguityLink['m_persIndex'])\n",
    "    _counter += ak.count_nonzero(events.Muons.EnergyLoss)\n",
    "    _counter += ak.count_nonzero(events.Jets.NNJvtPass)\n",
    "    _counter += ak.count_nonzero(events.Electrons.topoetcone20_CloseByCorr)\n",
    "    _counter += ak.count_nonzero(events.Electrons.topoetcone20ptCorrection)\n",
    "    _counter += ak.count_nonzero(events.Electrons.topoetcone20)\n",
    "    _counter += ak.count_nonzero(events.Muons.ptvarcone30_Nonprompt_All_MaxWeightTTVA_pt500_CloseByCorr)\n",
    "    _counter += ak.count_nonzero(events.Electrons.DFCommonElectronsECIDSResult)\n",
    "    _counter += ak.count_nonzero(events.Electrons.neflowisol20)\n",
    "    _counter += ak.count_nonzero(events.Muons.ptvarcone30_Nonprompt_All_MaxWeightTTVA_pt500)\n",
    "    _counter += ak.count_nonzero(events.Muons.ptcone40)\n",
    "    _counter += ak.count_nonzero(events.Muons.ptvarcone30_Nonprompt_All_MaxWeightTTVA_pt1000_CloseByCorr)\n",
    "    _counter += ak.count_nonzero(events.Muons.ptvarcone30_Nonprompt_All_MaxWeightTTVA_pt1000)\n",
    "    _counter += ak.count_nonzero(events.Muons.ptvarcone40)\n",
    "    _counter += ak.count_nonzero(events.Electrons.f1)\n",
    "    _counter += ak.count_nonzero(events.Muons.ptcone20_Nonprompt_All_MaxWeightTTVA_pt500)\n",
    "    _counter += ak.count_nonzero(events.PrimaryVertices.vertexType)\n",
    "    _counter += ak.count_nonzero(events.Muons.ptvarcone30)\n",
    "    _counter += ak.count_nonzero(events.Muons.ptcone30)\n",
    "    _counter += ak.count_nonzero(events.Muons.ptcone20_Nonprompt_All_MaxWeightTTVA_pt1000)\n",
    "    _counter += ak.count_nonzero(events.Electrons.ptvarcone30_Nonprompt_All_MaxWeightTTVALooseCone_pt500)\n",
    "    _counter += ak.count_nonzero(events.Muons.CaloLRLikelihood)\n",
    "\n",
    "    return {\"nevts\": num_events, \"_counter\": _counter}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f24e12-3fd8-481c-8318-7f9277f72c50",
   "metadata": {},
   "source": [
    "build a `fileset` using the list of files corresponding to some selected containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ef7dd8d-68e5-43fa-b8bf-5d8f972520c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileset summary\n",
      " - number of files: 4,722\n",
      " - total size: 6.704 TB\n",
      " - number of nevts: 441,089,000\n"
     ]
    }
   ],
   "source": [
    "# -------------\n",
    "# CONFIGURATION\n",
    "# -------------\n",
    "# modify this to change how many files are being processed\n",
    "# full list is list(find_containers.container_dict.keys()) + [\"data15_13TeV\", \"data16_13TeV\", \"data17_13TeV\", \"data18_13TeV\"]\n",
    "PROCESSES_TO_USE = [\"ttbar\"]  # 6.7 TB\n",
    "# PROCESSES_TO_USE = [\"db\", \"zjets\", \"wjets\", \"ttV\", \"othertop\", \"ttbar\"]  # all simulation, 48.4 TB\n",
    "# PROCESSES_TO_USE = [\"db\", \"zjets\", \"wjets\", \"ttV\", \"othertop\", \"ttbar\", \"data15_13TeV\", \"data16_13TeV\", \"data17_13TeV\", \"data18_13TeV\"]\n",
    "\n",
    "from input_files import find_containers\n",
    "\n",
    "\n",
    "def get_dsids(process):\n",
    "    if \"data\" not in process:\n",
    "        return find_containers.container_dict[process]\n",
    "    else:\n",
    "        return [process]\n",
    "\n",
    "\n",
    "with open(\"input_files/container_metadata.json\") as f:\n",
    "    container_metadata = json.load(f)  # name -> metadata\n",
    "\n",
    "\n",
    "container_to_file_list = {}  # container name -> list of files\n",
    "for container in sorted(glob.glob(\"input_files/file_lists/*txt\")):\n",
    "    container_name = container.split(\"/\")[-1:][0].replace(\"-\", \":\").replace(\".txt\", \"\")\n",
    "    with open(container) as f:\n",
    "        file_list = f.readlines()\n",
    "    container_to_file_list[container_name] = [p.strip() for p in file_list]\n",
    "\n",
    "\n",
    "fileset = defaultdict(lambda: defaultdict(dict))  # process -> list of files\n",
    "total_nfiles = 0\n",
    "total_size_TB = 0\n",
    "total_nevts = 0\n",
    "for process in PROCESSES_TO_USE:\n",
    "    dsids = get_dsids(process)\n",
    "    for dsid in dsids:\n",
    "        # find matching containers\n",
    "        matching_containers = [c for c in list(container_to_file_list.keys()) if str(dsid) in c]\n",
    "        # for each container, add full list of files\n",
    "        for container in matching_containers:\n",
    "            file_list = container_to_file_list[container]\n",
    "            total_nfiles += len(file_list)\n",
    "            assert len(file_list) == container_metadata[container][\"nfiles\"]\n",
    "            total_size_TB += container_metadata[container][\"size_TB\"]\n",
    "            total_nevts += container_metadata[container][\"nevts\"]\n",
    "            fileset[process][\"files\"].update(dict(zip(file_list, [\"CollectionTree\"]*len(file_list))))\n",
    "\n",
    "print(\"fileset summary\")\n",
    "print(f\" - number of files: {total_nfiles:,}\")\n",
    "print(f\" - total size: {total_size_TB:.3f} TB\")\n",
    "print(f\" - number of nevts: {total_nevts:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d59427f2-204b-4527-80fc-940f47407d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TTree 'CollectionTree' (1460 branches) at 0x7f26f6fb7760>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uproot.open({\"root://192.170.240.141//root://xrootd01.esc.qmul.ac.uk:1094//atlas/atlasdatadisk/rucio/mc20_13TeV/d9/56/DAOD_PHYSLITE.37231868._000002.pool.root.1\": \"CollectionTree\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb157621-90c5-4440-927b-a03c561c0d48",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "File did not open properly: [ERROR] Server responded with an error: [3005] Unable to open /root:/ftp1.ndgf.org:1094/atlas/disk/atlasdatadisk/rucio/mc20_13TeV/e7/3d/DAOD_PHYSLITE.37231882._000985.pool.root.1; protocol error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43muproot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mroot://192.170.240.143//root://ftp1.ndgf.org:1094//atlas/disk/atlasdatadisk/rucio/mc20_13TeV/e7/3d/DAOD_PHYSLITE.37231882._000985.pool.root.1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCollectionTree\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/venv/lib/python3.9/site-packages/uproot/reading.py:142\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(path, object_cache, array_cache, custom_classes, decompression_executor, interpretation_executor, **options)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file_path, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseek\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    135\u001b[0m ):\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a string, pathlib.Path, an object with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseek\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m methods, or a length-1 dict of \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mfile_path: object_path}, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m     )\n\u001b[0;32m--> 142\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[43mReadOnlyFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobject_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43marray_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marray_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecompression_executor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecompression_executor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterpretation_executor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpretation_executor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m object_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mroot_directory\n",
      "File \u001b[0;32m/venv/lib/python3.9/site-packages/uproot/reading.py:561\u001b[0m, in \u001b[0;36mReadOnlyFile.__init__\u001b[0;34m(self, file_path, object_cache, array_cache, custom_classes, decompression_executor, interpretation_executor, **options)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_before_create_source()\n\u001b[1;32m    558\u001b[0m source_cls, file_path \u001b[38;5;241m=\u001b[39m uproot\u001b[38;5;241m.\u001b[39m_util\u001b[38;5;241m.\u001b[39mfile_path_to_source_class(\n\u001b[1;32m    559\u001b[0m     file_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options\n\u001b[1;32m    560\u001b[0m )\n\u001b[0;32m--> 561\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_source \u001b[38;5;241m=\u001b[39m \u001b[43msource_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_before_get_chunks()\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin_chunk_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m _file_header_fields_big\u001b[38;5;241m.\u001b[39msize:\n",
      "File \u001b[0;32m/venv/lib/python3.9/site-packages/uproot/source/fsspec.py:55\u001b[0m, in \u001b[0;36mFSSpecSource.__init__\u001b[0;34m(self, file_path, **options)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n",
      "File \u001b[0;32m/venv/lib/python3.9/site-packages/uproot/source/fsspec.py:69\u001b[0m, in \u001b[0;36mFSSpecSource._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executor \u001b[38;5;241m=\u001b[39m FSSpecLoopExecutor()\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/venv/lib/python3.9/site-packages/fsspec_xrootd/xrootd.py:636\u001b[0m, in \u001b[0;36mXRootDFileSystem.open\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    635\u001b[0m     ac \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautocommit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intrans)\n\u001b[0;32m--> 636\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    645\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compr  \u001b[38;5;66;03m# type: ignore[import-not-found]\u001b[39;00m\n",
      "File \u001b[0;32m/venv/lib/python3.9/site-packages/fsspec_xrootd/xrootd.py:593\u001b[0m, in \u001b[0;36mXRootDFileSystem._open\u001b[0;34m(self, path, mode, block_size, autocommit, cache_options, **kwargs)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open\u001b[39m(\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    586\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    592\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m XRootDFile:\n\u001b[0;32m--> 593\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mXRootDFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/venv/lib/python3.9/site-packages/fsspec_xrootd/xrootd.py:699\u001b[0m, in \u001b[0;36mXRootDFile.__init__\u001b[0;34m(self, fs, path, mode, block_size, autocommit, cache_type, cache_options, size, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m status, _n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_myFile\u001b[38;5;241m.\u001b[39mopen(\n\u001b[1;32m    693\u001b[0m     fs\u001b[38;5;241m.\u001b[39mprotocol \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m://\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m fs\u001b[38;5;241m.\u001b[39mstorage_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhostid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m path,\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    695\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[1;32m    696\u001b[0m )\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m status\u001b[38;5;241m.\u001b[39mok:\n\u001b[0;32m--> 699\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile did not open properly: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetaOffset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[0;31mOSError\u001b[0m: File did not open properly: [ERROR] Server responded with an error: [3005] Unable to open /root:/ftp1.ndgf.org:1094/atlas/disk/atlasdatadisk/rucio/mc20_13TeV/e7/3d/DAOD_PHYSLITE.37231882._000985.pool.root.1; protocol error"
     ]
    }
   ],
   "source": [
    "uproot.open({\"root://192.170.240.143//root://ftp1.ndgf.org:1094//atlas/disk/atlasdatadisk/rucio/mc20_13TeV/e7/3d/DAOD_PHYSLITE.37231882._000985.pool.root.1\": \"CollectionTree\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1ecc41-0a72-44ec-a8b8-654286a02196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# pre-process\n",
    "samples, _ = dataset_tools.preprocess(fileset, step_size=1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca7b2ea-ae18-41ac-a4a8-cf257621dd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "BRANCH_LIST = [\n",
    "    \"AnalysisJetsAuxDyn.pt\",\n",
    "    \"AnalysisJetsAuxDyn.eta\",\n",
    "    \"AnalysisJetsAuxDyn.phi\",\n",
    "    \"AnalysisJetsAuxDyn.m\",\n",
    "    \"AnalysisElectronsAuxDyn.pt\",\n",
    "    \"AnalysisElectronsAuxDyn.eta\",\n",
    "    \"AnalysisElectronsAuxDyn.phi\",\n",
    "    \"AnalysisElectronsAuxDyn.m\",\n",
    "    \"AnalysisMuonsAuxDyn.pt\",\n",
    "    \"AnalysisMuonsAuxDyn.eta\",\n",
    "    \"AnalysisMuonsAuxDyn.phi\",\n",
    "    \"AnalysisJetsAuxDyn.EnergyPerSampling\",\n",
    "    \"AnalysisJetsAuxDyn.SumPtTrkPt500\",\n",
    "    \"AnalysisJetsAuxDyn.TrackWidthPt1000\",\n",
    "    \"PrimaryVerticesAuxDyn.z\",\n",
    "    \"PrimaryVerticesAuxDyn.x\",\n",
    "    \"PrimaryVerticesAuxDyn.y\",\n",
    "    \"AnalysisJetsAuxDyn.NumTrkPt500\",\n",
    "    \"AnalysisJetsAuxDyn.NumTrkPt1000\",\n",
    "    \"AnalysisJetsAuxDyn.SumPtChargedPFOPt500\",\n",
    "    \"AnalysisJetsAuxDyn.Timing\",\n",
    "    \"AnalysisJetsAuxDyn.JetConstitScaleMomentum_eta\",\n",
    "    \"AnalysisJetsAuxDyn.ActiveArea4vec_eta\",\n",
    "    \"AnalysisJetsAuxDyn.DetectorEta\",\n",
    "    \"AnalysisJetsAuxDyn.JetConstitScaleMomentum_phi\",\n",
    "    \"AnalysisJetsAuxDyn.ActiveArea4vec_phi\",\n",
    "    \"AnalysisJetsAuxDyn.JetConstitScaleMomentum_m\",\n",
    "    \"AnalysisJetsAuxDyn.JetConstitScaleMomentum_pt\",\n",
    "    \"AnalysisJetsAuxDyn.EMFrac\",\n",
    "    \"AnalysisJetsAuxDyn.Width\",\n",
    "    \"AnalysisJetsAuxDyn.ActiveArea4vec_m\",\n",
    "    \"AnalysisJetsAuxDyn.ActiveArea4vec_pt\",\n",
    "    \"AnalysisJetsAuxDyn.DFCommonJets_QGTagger_TracksWidth\",\n",
    "    \"AnalysisJetsAuxDyn.PSFrac\",\n",
    "    \"AnalysisJetsAuxDyn.JVFCorr\",\n",
    "    \"AnalysisJetsAuxDyn.DFCommonJets_QGTagger_TracksC1\",\n",
    "    \"AnalysisJetsAuxDyn.DFCommonJets_fJvt\",\n",
    "    \"AnalysisJetsAuxDyn.DFCommonJets_QGTagger_NTracks\",\n",
    "    \"AnalysisJetsAuxDyn.GhostMuonSegmentCount\",\n",
    "    \"AnalysisMuonsAuxDyn.muonSegmentLinks\",\n",
    "    \"AnalysisMuonsAuxDyn.msOnlyExtrapolatedMuonSpectrometerTrackParticleLink\",\n",
    "    \"AnalysisMuonsAuxDyn.extrapolatedMuonSpectrometerTrackParticleLink\",\n",
    "    \"AnalysisMuonsAuxDyn.inDetTrackParticleLink\",\n",
    "    \"AnalysisMuonsAuxDyn.muonSpectrometerTrackParticleLink\",\n",
    "    \"AnalysisMuonsAuxDyn.momentumBalanceSignificance\",\n",
    "    \"AnalysisMuonsAuxDyn.topoetcone20_CloseByCorr\",\n",
    "    \"AnalysisMuonsAuxDyn.scatteringCurvatureSignificance\",\n",
    "    \"AnalysisMuonsAuxDyn.scatteringNeighbourSignificance\",\n",
    "    \"AnalysisMuonsAuxDyn.neflowisol20_CloseByCorr\",\n",
    "    \"AnalysisMuonsAuxDyn.topoetcone20\",\n",
    "    \"AnalysisMuonsAuxDyn.topoetcone30\",\n",
    "    \"AnalysisMuonsAuxDyn.topoetcone40\",\n",
    "    \"AnalysisMuonsAuxDyn.neflowisol20\",\n",
    "    \"AnalysisMuonsAuxDyn.segmentDeltaEta\",\n",
    "    \"AnalysisMuonsAuxDyn.DFCommonJetDr\",\n",
    "    \"AnalysisMuonsAuxDyn.combinedTrackParticleLink\",\n",
    "    \"AnalysisMuonsAuxDyn.InnerDetectorPt\",\n",
    "    \"AnalysisMuonsAuxDyn.MuonSpectrometerPt\",\n",
    "    \"AnalysisMuonsAuxDyn.clusterLink\",\n",
    "    \"AnalysisMuonsAuxDyn.spectrometerFieldIntegral\",\n",
    "    \"AnalysisElectronsAuxDyn.ambiguityLink\",\n",
    "    \"AnalysisMuonsAuxDyn.EnergyLoss\",\n",
    "    \"AnalysisJetsAuxDyn.NNJvtPass\",\n",
    "    \"AnalysisElectronsAuxDyn.topoetcone20_CloseByCorr\",\n",
    "    \"AnalysisElectronsAuxDyn.topoetcone20ptCorrection\",\n",
    "    \"AnalysisElectronsAuxDyn.topoetcone20\",\n",
    "    \"AnalysisMuonsAuxDyn.ptvarcone30_Nonprompt_All_MaxWeightTTVA_pt500_CloseByCorr\",\n",
    "    \"AnalysisElectronsAuxDyn.DFCommonElectronsECIDSResult\",\n",
    "    \"AnalysisElectronsAuxDyn.neflowisol20\",\n",
    "    \"AnalysisMuonsAuxDyn.ptvarcone30_Nonprompt_All_MaxWeightTTVA_pt500\",\n",
    "    \"AnalysisMuonsAuxDyn.ptcone40\",\n",
    "    \"AnalysisMuonsAuxDyn.ptvarcone30_Nonprompt_All_MaxWeightTTVA_pt1000_CloseByCorr\",\n",
    "    \"AnalysisMuonsAuxDyn.ptvarcone30_Nonprompt_All_MaxWeightTTVA_pt1000\",\n",
    "    \"AnalysisMuonsAuxDyn.ptvarcone40\",\n",
    "    \"AnalysisElectronsAuxDyn.f1\",\n",
    "    \"AnalysisMuonsAuxDyn.ptcone20_Nonprompt_All_MaxWeightTTVA_pt500\",\n",
    "    \"PrimaryVerticesAuxDyn.vertexType\",\n",
    "    \"AnalysisMuonsAuxDyn.ptvarcone30\",\n",
    "    \"AnalysisMuonsAuxDyn.ptcone30\",\n",
    "    \"AnalysisMuonsAuxDyn.ptcone20_Nonprompt_All_MaxWeightTTVA_pt1000\",\n",
    "    \"AnalysisElectronsAuxDyn.ptvarcone30_Nonprompt_All_MaxWeightTTVALooseCone_pt500\",\n",
    "    \"AnalysisMuonsAuxDyn.CaloLRLikelihood\"\n",
    "]\n",
    "\n",
    "filter_name = lambda name: name in BRANCH_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15835a57-1182-4efb-8306-07f36af7a5b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# create the task graph\n",
    "# filter_name seems to not do anything here in terms of performance\n",
    "tasks = dataset_tools.apply_to_fileset(materialize_branches,\n",
    "                                       samples,\n",
    "                                       uproot_options={\"allow_read_errors_with_report\": True, \"filter_name\": filter_name},\n",
    "                                       schemaclass=PHYSLITESchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1953d6d",
   "metadata": {},
   "source": [
    "execute task graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6dfb17-6806-46c8-aa59-cd475e40cf64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# execute\n",
    "t0 = time.perf_counter()\n",
    "with performance_report(filename=\"dask-report.html\"):\n",
    "    ((out, report),) = dask.compute(tasks)  # feels strange that this is a tuple-of-tuple\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "print(f\"total time spent in uproot reading data: {ak.sum([v['duration'] for v in report.values()]):.2f} s\")\n",
    "print(f\"wall time: {t1-t0:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb47e9e5-57ea-4385-b8f8-b2a22ded030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"output: {out}\")\n",
    "\n",
    "print(\"\\nperformance metrics:\")\n",
    "\n",
    "event_rate = out[\"data\"][\"nevts\"] / (t1-t0)\n",
    "print(f\" - event rate: {event_rate / 1_000:.2f} kHz\")\n",
    "\n",
    "# need uproot>=5.3.2 to get these useful performance stats\n",
    "read_MB = sum(report['data']['performance_counters']['num_requested_bytes']) / 1_000**2\n",
    "rate_Mbs = read_MB / (t1-t0)\n",
    "print(f\" - read {read_MB:.2f} MB in {t1-t0:.2f} s -> {rate_Mbs:.2f} MBps (need to scale by x{200/8/rate_Mbs*1000:.0f} to reach 200 Gbps)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fb1ab6-0be4-4b99-942a-c1b53eda5639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check that the right colums are being touched\n",
    "dak.report_necessary_columns(tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e95cec3-d919-4973-9989-e343f6745199",
   "metadata": {},
   "source": [
    "## sanity check: read those columns without any Dask / coffea, compare footprint\n",
    "\n",
    "this does not scale and uses a single hardcoded file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49190b2a-0953-48b1-b56a-83b6e8298cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "branches_touched = list(list(dak.report_necessary_columns(tasks).values())[0])\n",
    "\n",
    "fname = \"/data/alheld/200gbps-atlas/data18_13TeV.periodAllYear.physics_Main.PhysCont.DAOD_PHYSLITE.grp18_v01_p6026/DAOD_PHYSLITE.37021624._000036.pool.root.1\"\n",
    "t = uproot.open({fname: \"CollectionTree\"})\n",
    "\n",
    "initial_size_in_MB = t.file.source.num_requested_bytes/1000**2  # non-zero at the start (some metadata read)\n",
    "\n",
    "t.arrays(branches_touched)\n",
    "\n",
    "new_size_in_MB = t.file.source.num_requested_bytes/1000**2\n",
    "print(initial_size_in_MB, new_size_in_MB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4f9b10-ece8-4a8b-bf39-b3994cb78bcb",
   "metadata": {},
   "source": [
    "This should match the numbers reported above through coffea, but it currently does not! This needs to be understood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d083e1b1-76b6-40cd-8602-215e652a1ca5",
   "metadata": {},
   "source": [
    "## rest of the notebook: non-Dask / non-coffea local tests for performance comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acaa518-16e2-444b-b086-d778fb096163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time each branch individually, compare to size of the branch, ensure no extreme outliers are present\n",
    "for i in range(len(BRANCH_LIST)):\n",
    "    with uproot.open({fname: treename}, filter_name=filter_name) as f:\n",
    "        initial_metadata_in_MB = f.file.source.num_requested_bytes/1000**2\n",
    "        t0 = time.perf_counter()\n",
    "        f[BRANCH_LIST[i]].array()\n",
    "        t1 = time.perf_counter()\n",
    "        new_size_in_MB = f.file.source.num_requested_bytes/1000**2\n",
    "        time_ms = (t1-t0)*1000\n",
    "        size_MB = (new_size_in_MB-initial_metadata_in_MB)\n",
    "        print(f\"{BRANCH_LIST[i]:<80}: {time_ms:4.0f} ms\\t\\t{size_MB:>5.2f} MB\\t\\t{size_MB / time_ms * 1000:>5.1f} MB/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e321f6-3ae6-4af3-a9e3-b7e5e469cffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_size = os.path.getsize(fname) / 1000**2  # all sizes in MB\n",
    "\n",
    "time_per_fraction_read = {}\n",
    "for i in range(len(BRANCH_LIST)//12+1):\n",
    "    with uproot.open({fname: treename}, filter_name=filter_name) as f:  # re-open every time for accurate tracking of data read\n",
    "        branches = BRANCH_LIST[0:(i+1)*12]\n",
    "        print(f\"reading {len(branches)} branch(es)\")\n",
    "        initial_metadata_in_MB = f.file.source.num_requested_bytes/1000**2\n",
    "        t0 = time.perf_counter()\n",
    "        f.arrays(branches)\n",
    "        t1 = time.perf_counter()\n",
    "        new_size_in_MB = f.file.source.num_requested_bytes/1000**2\n",
    "        fraction_read = (new_size_in_MB - initial_metadata_in_MB) / file_size\n",
    "        time_per_fraction_read[fraction_read] = t1 - t0\n",
    "        print(f\"  - read {new_size_in_MB - initial_metadata_in_MB:.2f} MB in {t1 - t0:.2f} s\")\n",
    "\n",
    "with uproot.open({fname: treename}) as f:\n",
    "    nevts = f.num_entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d3a221-7f9e-4a7c-aeb3-571d117398c8",
   "metadata": {},
   "source": [
    "The fraction of the file being depends on the file type and may differ from data, where the derivation of these branches was performed to hit 25%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8b860f-5df8-4fad-b405-8c8d2e7fc871",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in time_per_fraction_read.items():\n",
    "    print(f\"fraction read: {k:.2%} in {v:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f10517f-c2bf-4155-a829-2123a828386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_rate_in_kHz = nevts / np.fromiter(time_per_fraction_read.values(), np.float32) / 1_000\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(figsize=(12,4), ncols=2)\n",
    "\n",
    "ax0.plot(time_per_fraction_read.keys(), time_per_fraction_read.values(), \"o\")\n",
    "ax0.set_xlabel(\"fraction read\")\n",
    "ax0.set_ylabel(\"time [s]\")\n",
    "ax0.set_xlim([0, ax0.get_xlim()[1]])\n",
    "ax0.set_ylim([0, ax0.get_ylim()[1]])\n",
    "\n",
    "ax1.plot(time_per_fraction_read.keys(), event_rate_in_kHz, \"o\")\n",
    "ax1.set_xlabel(\"fraction read\")\n",
    "ax1.set_ylabel(\"event rate [kHz]\")\n",
    "ax1.set_xlim([0, ax1.get_xlim()[1]])\n",
    "ax1.set_ylim([0, ax1.get_ylim()[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6889dc-52a3-40d1-8e65-f8317437035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pure \"metadata\" (?) part, would be read on every open call\n",
    "with uproot.open({fname: treename}) as f:\n",
    "    print(f\"{f.file.source.num_requested_bytes/1000**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d41622a-a7ba-41d6-a818-d1147e1f9213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction read * file size (in MB) * 8 (to Mb) / time (in s)\n",
    "io_in_Mbps = np.fromiter(time_per_fraction_read.keys(), np.float32) * file_size * 8 / np.fromiter(time_per_fraction_read.values(), np.float32)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(time_per_fraction_read.keys(), io_in_Mbps, \"o\")\n",
    "ax.set_xlabel(\"fraction read\")\n",
    "ax.set_ylabel(\"rate [Mbps]\")\n",
    "ax.set_xlim([0, ax.get_xlim()[1]])\n",
    "ax.set_ylim([0, ax.get_ylim()[1]])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "all,-jupytext.text_representation.jupytext_version"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
